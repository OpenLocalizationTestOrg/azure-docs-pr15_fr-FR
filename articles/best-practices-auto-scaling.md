<properties
   pageTitle="Conseils AutoScaling | Microsoft Azure"
   description="Conseils sur l’échelle pour allouer dynamiquement des ressources requis par une application."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="christb"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="07/13/2016"
   ms.author="masashin"/>

# <a name="autoscaling-guidance"></a>Conseils AutoScaling

[AZURE.INCLUDE [pnp-header](../includes/guidance-pnp-header-include.md)]

## <a name="overview"></a>Vue d’ensemble
AutoScaling est le processus d’allocation dynamiquement les ressources requises par une application pour répondre aux exigences de performances et répondre aux niveaux de service (accords), et en limitant les coûts d’exécution. Au fur et à mesure du volume de travail, une application peut nécessiter des ressources supplémentaires pour lui permettre d’effectuer ses tâches rapidement. À la demande slackens, ressources peuvent être supprimer l’allocation pour réduire les coûts, tout en toujours maintenir des performances optimales et SLA.
AutoScaling exploite l’élasticité des environnements hébergé sur le nuage tout en facilitant des frais de gestion. Ceci est effectué en réduisant la nécessité d’un opérateur pour surveiller les performances d’un système en permanence et prendre des décisions sur l’ajout ou suppression des ressources.
>[AZURE.NOTE] AutoScaling s’applique à toutes les ressources utilisées par une application, pas seulement les ressources de calcul. Par exemple, si votre système utilise des files d’attente pour envoyer et recevoir des informations, il peut créer files d’attente supplémentaires fil des besoins.

## <a name="types-of-scaling"></a>Types de mise à l’échelle
Mise à l’échelle généralement prend l’une des deux formes suivantes :

- **Vertical** (souvent appelées _et vers le bas jusqu'à la mise à l’échelle_). Ce formulaire que vous devez modifier le matériel (développer ou réduire sa capacité et performances), ou redéployez la solution à l’aide de remplacement matériel qui possède la capacité appropriée et les performances. Dans un environnement cloud, la plate-forme matérielle est généralement un environnement virtualisé. À moins que le matériel d’origine a été sensiblement overprovisioned, avec les frais qui en résulte de capitaux instants, verticalement mise à l’échelle vers le haut dans cet environnement entraîne la mise en service des ressources plus importants, puis en déplaçant le système sur ces nouvelles ressources. Mise à l’échelle verticale est souvent un processus interruption de service qui exige d’effectuer le système temporairement indisponible pendant qu’il est redéployé. Il est possible de maintenir le système d’origine en cours d’exécution alors que le nouveau matériel est mis en service et mis en ligne, mais il est probable que certains interrompu pendant les transitions de traitement de l’environnement ancien vers le nouveau. Il est courant autoscaling permet de mettre en œuvre une stratégie de mise à l’échelle verticale.
- **Horizontal** (souvent appelé _mise à l’échelle, puis dans_). Ce formulaire requiert le déploiement de la solution sur plus ou moins de ressources, qui sont généralement ressources marchandise plutôt que des systèmes puissante. La solution puisse continuer sans interruption pendant que ces ressources sont mis en service. Une fois le processus de configuration terminée, copies d’éléments formant la solution peuvent être déployés sur ces ressources supplémentaires et accessibles. Si la demande est, les ressources supplémentaires peuvent être récupérées une fois que les éléments à l’aise ont été arrêtés correctement. Nombre de systèmes sur le nuage, y compris Microsoft Azure, prend en charge l’automation de cette forme de mise à l’échelle.

## <a name="implement-an-autoscaling-strategy"></a>Mettre en œuvre une stratégie autoscaling
Implémentation d’une stratégie autoscaling généralement requiert les composants et les processus suivants :

- Instrumentation et systèmes au niveau de l’application, service et infrastructure de surveillance. Ces systèmes capturent des mesures clés, tels que des temps de réponse, files d’attente, de l’UC et utilisation de la mémoire.
- Logique de prise de décision qui peut évaluer les facteurs d’échelle contrôlées par rapport à des seuils système prédéfinies ou les plannings et prendre des décisions quant à l’échelle ou non.
- Composants qui sont chargés d’effectuer les tâches liées à la mise à l’échelle du système, telles que la mise en service ou de désactivation des comptes ressources.
- Test, de surveillance et d’optimisation de la stratégie autoscaling pour vérifier qu’il fonctionne comme prévu.

La plupart des environnements sur le nuage, par exemple Azure, fournissent des mécanismes intégrés autoscaling scénarios courants adresse. Si l’environnement ou le service que vous utilisez ne fournit pas que nécessaires automatisé fonctionnalité mise à l’échelle, ou si vous avez des besoins autoscaling extrême au-delà de ses capacités, une mise en œuvre personnalisée peut être nécessaire. Utiliser cette implémentation personnalisée collecter opérationnelles et les mesures de système, les analyser pour identifier les données pertinentes et échelle puis ressources en conséquence.


## <a name="configure-autoscaling-for-an-azure-solution"></a>Configurer autoscaling pour une solution Azure
Il existe plusieurs options de configuration autoscaling pour vos solutions Azure :

- **Échelle Azure** prend en charge les scénarios les plus courants mise à l’échelle en fonction d’une planification et, facultativement, déclenchée mise à l’échelle opérations basées sur les mesures de runtime (par exemple, l’utilisation du processeur, file d’attente ou les compteurs intégrés et personnalisés). Vous pouvez configurer des stratégies d’autoscaling simple pour une solution rapidement et facilement à l’aide du portail Azure. Pour un contrôle plus détaillé, vous pouvez apporter utiliser de l' [API REST de gestion des services Azure](https://msdn.microsoft.com/library/azure/ee460799.aspx) ou de l' [REST API de gestionnaire de ressources Azure](https://msdn.microsoft.com//library/azure/dn790568.aspx). La [Bibliothèque de gestion des services Azure surveillance](http://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring) et la [Microsoft Insights bibliothèque](https://www.nuget.org/packages/Microsoft.Azure.Insights/) (preview) sont SDK qui permettre de collecte des indicateurs à partir des différentes ressources et effectuer autoscaling à l’aide d’utiliser des API REST. Pour les ressources dans lesquelles prise en charge du Gestionnaire de ressources Azure n’est pas disponible, ou si vous utilisez les Services de Cloud Azure, l’API REST de gestion des services peuvent servir pour autoscaling. Dans tous les autres cas, utilisez le Gestionnaire de ressources Azure.
- **Une solution personnalisée**, selon votre instrumentation dans l’application et les fonctionnalités de gestion de Azure, peuvent être utiles. Par exemple, vous pouvez utiliser les diagnostics de Windows Azure ou les autres méthodes d’instrumentation dans votre application, ainsi que de code personnalisé pour surveiller en permanence et exporter des indicateurs de l’application. Vous pouvez y règles personnalisées qui fonctionnent sur les mesures et utilisez la gestion des services ou REST API Gestionnaire de ressources du déclencher autoscaling. Les mesures pour déclencher une opération de mise à l’échelle peuvent être n’importe quel compteur prédéfini ou personnalisé ou autres instrumentation que vous implémentez au sein de l’application. Toutefois, une solution personnalisée n’est pas simple mettre en œuvre et doit être considéré comme uniquement si aucun des approches précédents peut répondre à vos besoins. Le [Bloc d’Application Autoscaling](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx) utilise cette approche.
- **Les services tiers**, tels [Paraleap AzureWatch](http://www.paraleap.com/AzureWatch), permettent à l’échelle d’une solution basée sur les calendriers, des indicateurs de performance charge et système de service, règles personnalisées et combinaisons de différents types de règles.

Lors du choix de la solution autoscaling à adopter, tenez compte des points suivants :

- Utilisez les fonctionnalités autoscaling intégrés de la plateforme, si elles peuvent répondre à vos besoins. Si ce n’est pas le cas, si vous avez réellement besoin des fonctionnalités de mise à l’échelle plus complexes avec soin. Quelques exemples de configuration requise supplémentaire peuvent inclure plus fine du contrôle, méthodes permettant de détecter les événements déclencheurs pour la mise à l’échelle, mise à l’échelle abonnements et mise à l’échelle d’autres types de ressources.
- Vous pouvez si vous pouvez prévoir la charge de l’application avec une précision suffisante pour dépendent uniquement autoscaling planifiée (ajout et suppression d’instances pour répondre aux anticipé pointes de la demande). Où il n’est pas possible, utilisez autoscaling réactive sur base des métriques collectées en cours d’exécution, pour permettre à l’application pour gérer les modifications inattendues dans la demande. En règle générale, vous pouvez combiner ces approches. Par exemple, créer une stratégie qui ajoute des ressources comme cluster, le stockage et files d’attente, en fonction d’une planification des moments lorsque vous connaissez que l’application n’est plus occupé (e). Cela permet de vous assurer que la capacité est disponible lorsque cela est nécessaire, sans retard rencontré lors du démarrage de nouvelles instances. En outre, pour chaque règle planifiée, définir des indicateurs qui permettent autoscaling réactif pendant cette période pour vous assurer que l’application peut gérer prolongées mais inattendus pointes de la demande.
- Il est souvent difficile à comprendre la relation entre les besoins de mesures et à la capacité, en particulier lorsqu’une application est déployée initiale. Vous préférez un peu capacité supplémentaire au début, de mise en service et puis surveiller et optimiser les règles autoscaling pour placer la capacité rapprocher à la charge réelle.

### <a name="use-azure-autoscale"></a>Utiliser une échelle Azure
Échelle automatique vous permet de configurer mise à l’échelle et mettre à l’échelle dans les options pour une solution. Échelle pouvez automatiquement ajouter et supprimer des instances de web Services Cloud Azure et rôles collaborateur, Azure Mobile Services et applications Web fonctionnalité dans le Service d’application Azure. Il peut également activer échelle automatique par démarrer et arrêter les instances du Machines virtuelles Azure. Une stratégie autoscaling Azure inclut deux ensembles de facteurs :

- Autoscaling échéancier qui permet de garantir des instances supplémentaires sont disponibles à correspondent à un pic attendu de l’utilisation et peuvent mettre à l’échelle dans une fois que l’heure de pointe est passée. Cela vous permet de vous assurer que vous avez suffisamment instances déjà en cours d’exécution, sans attendre que le système de réagir à la charge.
- Autoscaling métriques qui réagit aux facteurs tels que la moyenne de l’UC sur la dernière heure ou la file d’attente des messages que la solution s’exécute dans un espace de stockage Azure ou file d’attente Bus des services Azure. Cela permet à l’application de réagir séparément à partir des règles autoscaling planifiée pour s’adapter aux modifications non planifiées ou inattendues à la demande.

Tenez compte des points suivants lorsque vous utilisez échelle automatique :

- Votre stratégie autoscaling combine la mise à l’échelle planifiée et basée sur les indicateurs. Vous pouvez spécifier les deux types de règles d’un service.
- Configurer les règles autoscaling et puis surveiller les performances de votre application dans le temps. Utiliser les résultats de cette surveillance ajuster la façon dont dans lequel le système évolue si nécessaire. Cependant, gardez à l’esprit qu’autoscaling n’est pas un processus instantané. Le temps de réagir à une mesure telle que moyenne processeur utilisation dépassant (ou au-dessous) est un seuil spécifié.
- Règles AutoScaling qui utilisent un mécanisme de détection basé sur un attribut déclencheur mesurée (par exemple, la longueur de file d’attente ou l’utilisation du processeur) utilisent une valeur d’agrégation sur, au lieu de valeurs instantanées, pour déclencher une action autoscaling. Par défaut, l’agrégat est une moyenne des valeurs. Ainsi, le système de réagir trop rapidement ou à l’origine d’oscillation rapide. Il permet également de temps pour les nouvelles instances sont démarrage automatique de régler en mode, empêchant actions autoscaling supplémentaires de se produire pendant la nouvelle instance est démarrage en cours d’exécution. Pour les Services en nuage Azure et Machines virtuelles Azure, le délai par défaut pour l’agrégation est 45 minutes, donc il peut prendre jusqu'à cet intervalle de temps pour la mesure déclencher autoscaling en réponse à deux pointes dans la demande. Vous pouvez modifier la période d’agrégation à l’aide du Kit de développement, mais n’oubliez pas que les périodes de moins de 25 minutes peuvent entraîner des résultats inattendus (pour plus d’informations, voir [Automatique mise à l’échelle Cloud Services sur un pourcentage processeur avec la bibliothèque de gestion des Services de surveillance Azure](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/)). Pour les applications Web, la période considérée est plus courte, ce qui permet de nouvelles instances soit disponible dans environ 5 minutes après une modification de la mesure déclencheur moyenne.
- Si vous configurez autoscaling utilise le Kit de développement plutôt que le portail web, vous pouvez spécifier une planification plus détaillée pendant lequel les règles sont actives. Vous pouvez également créer vos propres indicateurs et les utiliser avec ou sans un des fonctionnalités existantes dans votre autoscaling les règles. Par exemple, vous souhaiterez peut-être utilisez compteurs de remplacement, telles que le nombre de requêtes par seconde ou la disponibilité de la mémoire moyenne, ou personnalisés compteurs décrivant des processus métiers spécifiques.
- Lorsque autoscaling Machines virtuelles Azure, vous devez déployer un nombre d’instances de la machine virtuelle est égal au nombre maximal vous permettra autoscaling Démarrer. Ces instances doivent faire partie du même jeu de disponibilité. Machines virtuelles autoscaling mécanisme ne pas créer ou supprimer des instances de la machine virtuelle ; en revanche, les règles autoscaling que vous configurez démarre et arrêter un nombre de ces instances approprié. Pour plus d’informations, voir [Ajuster automatiquement une application Web rôles, rôles de travail ou Machines virtuelles en cours d’exécution](./cloud-services/cloud-services-how-to-scale.md).
- Si les nouvelles instances ne peut pas être démarrés, peut-être parce que la valeur maximale pour un abonnement a été atteinte ou une erreur se produit lors du démarrage, le portail peut afficher qu’une opération autoscaling a réussi. Toutefois, les événements suivants **ChangeDeploymentConfiguration** affichées dans le portail affiche uniquement qu’un démarrage du service a été demandé et il n’y ait aucun événement pour indiquer qu’elle a été terminée avec succès.
- Vous pouvez utiliser l’interface utilisateur du portail web pour lier des ressources telles que des instances de base de données SQL et files d’attente à une instance de service cluster. Cela vous permet d’accéder plus facilement aux particulières manuels et automatiques mise à l’échelle des options de configuration pour chacune des ressources liées. Pour plus d’informations, voir [Comment : lier une ressource à un service cloud](cloud-services-how-to-manage.md#linkresources) et [comment adapter une Application](./cloud-services/cloud-services-how-to-scale.md).
- Lorsque vous configurez plusieurs règles et les stratégies, ils peuvent entrer en conflit avec eux. Échelle utilise les règles de résolution de conflits suivantes pour vous assurer qu’il existe toujours un nombre suffisant d’instances en cours d’exécution :
  - Échelle des opérations ont toujours priorité sur échelle dans les opérations.
  - Lorsque évoluer conflit opérations, la règle qui lance l’augmentation du plus grand nombre d’instances est prioritaire.
  - Quand mettre à l’échelle en conflit opérations, la règle qui lance la diminution plus petit nombre d’instances est prioritaire.

<a name="the-azure-monitoring-services-management-library"></a>

## <a name="application-design-considerations-for-implementing-autoscaling"></a>Considérations de conception d’application pour l’implémentation autoscaling
AutoScaling n’est pas une solution instantanée. Simplement ajouter des ressources à un système ou plusieurs instances d’un processus en cours d’exécution ne garantit que contribue à améliorer les performances du système. Lorsque vous concevez une stratégie autoscaling, tenez compte des points suivants :

- Le système doit être conçu pour être scalable horizontalement. Éviter les hypothèses sur affinité d’instance ; ne concevez pas les solutions qui requièrent que le code est toujours en cours d’exécution dans une instance spécifique d’un processus. Lors de la mise à l’échelle un site web ou un service cloud horizontalement, ne part du principe qu’une série de demandes de la même source doivent toujours être routée vers la même instance. Pour la même raison, services sans état pour éviter une série de requêtes à partir d’une application pour toujours être routés vers la même instance d’un service de conception. Lorsque vous créez un service qui lit les messages à partir d’une file d’attente et les traite, ne pas apporter les hypothèses sur quelle instance des poignées de service un message spécifique. AutoScaling pu démarrer des instances supplémentaires d’un service fur et à la file d’attente. La [Concurrence consommateurs motif](http://msdn.microsoft.com/library/dn568101.aspx) décrit comment gérer ce scénario.
- Si la solution met en œuvre une tâche longue, concevoir cette tâche pour prendre en charge à la fois l’évolution horizontale et la même échelle dans. Sans date d’échéance soins, une telle tâche susceptibles d’empêcher une instance d’un processus d’arrêt proprement lorsque le système évolue dans ou qu’il pourrait perdre des données si le processus est interrompu force. Dans l’idéal, refactoriser une tâche longue et diviser le traitement qu’il exécute en segments plus petits et discrètes. [Canaux et filtres motif](http://msdn.microsoft.com/library/dn568100.aspx) fournit un exemple de comment vous pouvez y parvenir.
- Par ailleurs, vous pouvez implémenter un mécanisme de point de contrôle enregistrements d’informations sur la tâche à intervalles réguliers l’état et les enregistrement cet état dans le stockage résistant accessible par n’importe quelle instance du processus de la tâche en cours d’exécution. De cette façon, si le processus est arrêté, le travail qu’elle a été effectue puisse reprendre le dernier point de contrôle à l’aide d’une autre instance.
- Lors de tâches en arrière-plan effectuer sur des instances de calcul distincte, tels que le travail rôles des services cloud hébergée application, vous devrez peut-être mettre à l’échelle différentes parties de l’application à l’aide de stratégies de mise à l’échelle différents. Par exemple, vous devrez peut-être déployer cluster d’interface utilisateur utilisateur supplémentaires instances sans augmenter le nombre de l’arrière-plan de calculent instances ou à l’opposé de ce. Si vous offrez différents niveaux de service (service premium et de base, par exemple), vous devrez peut-être évoluer les ressources de calcul pour les packages de service premium plus agressif que celles des packages service base afin de respecter les SLA.
- Envisagez d’utiliser la longueur de la file d’attente sur laquelle l’interface utilisateur et l’arrière-plan calculent instances communiquent en tant que critère pour votre stratégie autoscaling. Il s’agit du meilleur indicateur d’un déséquilibre ou la différence entre la charge et la capacité de traitement de la tâche en arrière-plan.
- Si vous basez votre stratégie autoscaling sur compteurs décrivant le processus d’entreprise, telles que le nombre de commandes passées par heure ou le temps d’exécution moyen d’une transaction complexe, assurez-vous de comprendre entièrement la relation entre les résultats de ces types de compteurs et les besoins en capacité cluster réel. Il peut être nécessaire à l’échelle plusieurs composants ou calculer unité en réponse aux modifications dans la zone compteurs de processus métier.  
- Pour empêcher un système d’essayer de faire évoluer excessive et pour éviter les coûts liés à des milliers d’instances en cours d’exécution, pensez à limiter le nombre maximal d’instances pouvant être ajoutées automatiquement. La plupart des mécanismes autoscaling permettent de spécifier le nombre maximal et minimal d’instances d’une règle. En outre, vous pouvez normalement dégrader la fonctionnalité fournie par le système si le nombre maximal d’instances déployé et le système n’est toujours surchargé.
- Gardez à l’esprit qu’autoscaling peut-être ne pas être le moyen le plus approprié pour gérer un soudain rupture de charge de travail. Il prend du temps pour la mise en service et démarrer la nouvelle instance d’un service ou ajouter des ressources à un système, et la demande pointe peut se sont écoulés au moment où que ces ressources supplémentaires ont été apportées disponibles. Dans ce scénario, il peut être préférable de limiter le service. Pour plus d’informations, voir la [La limitation de motif](http://msdn.microsoft.com/library/dn589798.aspx).
- En revanche, si vous avez besoin de la capacité de traiter toutes les demandes lorsque le volume varie rapidement et coût n’est pas un facteur contribuant principal, envisagez d’utiliser une stratégie autoscaling agressif qui démarre plus rapidement des instances supplémentaires. Vous pouvez également utiliser une stratégie planifiée, qui démarre un nombre suffisant d’instances pour répondre à la charge maximale avant qu’une charge est prévue.
- Le mécanisme autoscaling doit surveiller le processus autoscaling et consigner les détails de chaque événement autoscaling (ce qui a déclenché il, les ressources qui ont été ajoutés ou supprimés et quand). Si vous créez un mécanisme autoscaling personnalisé, assurez-vous qu’il comprend cette fonctionnalité. Analyser les informations qui permettent de mesurer l’efficacité de la stratégie autoscaling et adaptez-le si nécessaire. Vous pouvez régler les deux à court terme, comme les modèles d’utilisation sont plus évidente et plus long terme, que l’entreprise développe ou évolue la configuration requise de l’application. Si une application atteint la limite supérieure définie pour autoscaling, le mécanisme peut prévenir également un opérateur qui peut démarrer manuellement des ressources supplémentaires si nécessaire. Notez que, dans ces conditions, l’opérateur peut également être responsable de la suppression manuelle de ces ressources après facilite la charge de travail.

## <a name="related-patterns-and-guidance"></a>Conseils et des modèles connexes
Les modèles et les conseils suivants peuvent également être pertinents pour votre scénario lors de l’implémentation autoscaling :

- [La limitation de motif](http://msdn.microsoft.com/library/dn589798.aspx). Ce modèle décrit comment une application peut continuer à fonctionner et SLA lorsqu’une augmentation de la demande place une charge extrême sur les ressources. La limitation peut être utilisée avec autoscaling pour empêcher un système d’être dépassé pendant que le système peut évoluer.
- [En patinage consommateurs motif](http://msdn.microsoft.com/library/dn568101.aspx). Ce modèle décrit comment mettre en œuvre d’un groupe d’instances de service qui peuvent gérer les messages à partir d’une instance de l’application. AutoScaling peut être utilisé pour démarrer et arrêter les instances de service pour correspondre à la charge de travail escomptée. Cette approche permet à un système de traiter plusieurs messages simultanément pour optimiser le débit, améliorer la disponibilité et extensibilité élevées et équilibrer la charge de travail.
- [Instructions de télémétrie et d’instrumentation](http://msdn.microsoft.com/library/dn589775.aspx). Instrumentation et télémétrie sont essentiels pour recueillir les informations susceptibles de conduire le processus autoscaling.

## <a name="more-information"></a>Plus d’informations
- [Comment mettre à l’échelle d’une Application](./cloud-services/cloud-services-how-to-scale.md)
- [Ajuster automatiquement une application Web rôles, rôles de travail ou Machines virtuelles en cours d’exécution](cloud-services-how-to-manage.md#linkresources)
- [Comment : lier une ressource à un service cloud](cloud-services-how-to-manage.md#linkresources)
- [Mettre les ressources liées à l’échelle](./cloud-services/cloud-services-how-to-scale.md#scale-link-resources)
- [Azure bibliothèque de gestion des Services de surveillance](http://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Monitoring)
- [Gestion des services Azure API REST](http://msdn.microsoft.com/library/azure/ee460799.aspx)
- [Azure API REST de gestionnaire de ressources](https://msdn.microsoft.com/library/azure/dn790568.aspx)
- [Bibliothèque Microsoft Insights](https://www.nuget.org/packages/Microsoft.Azure.Insights/)
- [Opérations sur Autoscaling](http://msdn.microsoft.com/library/azure/dn510374.aspx)
- [Namespace Microsoft.WindowsAzure.Management.Monitoring.Autoscale](http://msdn.microsoft.com/library/azure/microsoft.windowsazure.management.monitoring.autoscale.aspx)
