<properties
    pageTitle="Importer des données dans Machine apprentissage Studio de sources de données en ligne | Microsoft Azure"
    description="Comment importer vos données de formation Azure Machine apprentissage Studio provenant de diverses sources en ligne."
    keywords="importer des données, format des données, les types de données, des sources de données, les données de formation"
    services="machine-learning"
    documentationCenter=""
    authors="bradsev"
    manager="jhubbard"
    editor="cgronlun"/>

<tags
    ms.service="machine-learning"
    ms.workload="data-services"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="09/19/2016"
    ms.author="bradsev;garye" />


# <a name="import-data-into-azure-machine-learning-studio-from-various-online-data-sources-with-the-import-data-module"></a>Importer des données dans Azure Machine apprentissage Studio de diverses sources de données en ligne avec le module d’importer des données

Cet article décrit la prise en charge pour l’importation de données en ligne à partir de différentes sources et les informations nécessaires pour déplacer des données provenant de ces sources dans une expérience d’apprentissage automatique Azure.

> [AZURE.NOTE] Cet article fournit des informations générales sur l' [Importation de données] [ import-data] module. Pour plus d’informations sur les types de données, vous pouvez accéder, formats, les paramètres et les réponses aux questions courantes, consultez la rubrique de référence de module pour [Importer des données] [ import-data] module.

<!-- -->

[AZURE.INCLUDE [import-data-into-aml-studio-selector](../../includes/machine-learning-import-data-into-aml-studio.md)]

## <a name="introduction"></a>Introduction

Vous pouvez accéder aux données à partir de dans Azure Machine apprentissage Studio à partir de plusieurs sources de données en ligne pendant l’exécution de votre expérience en utilisant les [Importer des données] [ import-data] module :

- Une URL Web à l’aide de HTTP
- Hadoop à l’aide de HiveQL
- Stockage d’objets blob Azure
- Table Azure
- Base de données SQL Azure ou de SQL Server sur machine virtuelle Azure
- Base de données SQL Server en local
- Un flux OData actuellement fournisseur de données
 
Flux de travail de réalisation expériences dans Azure Machine apprentissage Studio se compose de composants de glisser-déplacer sur la zone de dessin. Pour accéder à des sources de données en ligne, ajoutez les [Importer des données] [ import-data] module à votre expérience, sélectionner la **source de données**et puis fournir les paramètres nécessaires pour accéder aux données. Les sources de données en ligne qui sont prises en charge sont répertoriés dans le tableau ci-dessous. Le tableau suivant résume également les formats de fichier pris en charge et les paramètres qui sont utilisés pour accéder aux données.

Notez que parce que cette formation d’accès aux données pendant l’exécution de votre expérience, il est disponible uniquement dans cette expérience. Par comparaison, les données qui ont été stockées dans un module de jeu de données sont disponibles pour une expérience dans votre espace de travail.

> [AZURE.IMPORTANT] Pour l’instant, les [Importer des données] [ import-data] et [Exporter des données] [ export-data] modules peuvent lire et écrire des données uniquement à partir du stockage Azure créé à l’aide du modèle de déploiement classique. En d’autres termes, le nouveau type de compte de stockage d’objets Blob Azure qui propose un niveau d’accès de stockage actif ou le niveau d’accès de stockage pouvant être ajoutées n'est pas encore pris en charge. 

> En règle générale, les comptes de stockage Azure que vous avez peut-être créés avant cette option service devient disponible ne doivent pas être affectées. Si vous avez besoin créer un nouveau compte, sélectionnez **classique** pour le modèle de déploiement, ou utilisez le Gestionnaire de ressources et pour le **type de compte**, sélectionnez **Général** au lieu de **stockage d’objets Blob**. 

> Pour plus d’informations, voir [stockage d’objets Blob Azure : niveaux de stockage actif et pouvant être ajoutées](../storage/storage-blob-storage-tiers.md).



## <a name="supported-online-data-sources"></a>Prise en charge des sources de données en ligne
Module d’apprentissage automatique **Importer des données** Azure prend en charge les sources de données suivantes :

Source de données | Description | Paramètres |
---|---|---|
URL Web via le protocole HTTP |Lit les données dans des valeurs séparées par des virgules (CSV), valeurs séparées par des tabulations (TSV), format de fichier de relation d’attribut (ARFF) et formats de prise en charge vecteur Machines (SVM-clair), à partir de n’importe quel URL web qui utilise le protocole HTTP | <b>URL</b>: Spécifie le nom complet du fichier, y compris l’URL du site et le nom du fichier, avec toutes les extensions. <br/><br/><b>Format des données</b>: Spécifie une des données pris en charge les formats : CSV, TSV, ARFF ou SVM lumière. Si les données comportent une ligne d’en-tête, il est utilisé pour attribuer des noms de colonne.|
Hadoop/HADOOP|Lit les données à partir du stockage distribué Hadoop. Vous spécifiez les données souhaitées à l’aide de HiveQL, un langage de requête de type SQL. HiveQL peut également servir pour agréger des données et effectuer de filtrage avant d’ajouter les données à Studio d’apprentissage automatique des données.|<b>Ruche requête de base de données</b>: Spécifie la requête Hive utilisée pour générer les données.<br/><br/><b>URI du serveur HCatalog</b> : spécifié le nom de votre cluster en utilisant le format * &lt;votre nom de cluster&gt;. azurehdinsight.net.*<br/><br/><b>Nom du compte utilisateur Hadoop</b>: indique le nom de compte d’utilisateur Hadoop utilisé pour le cluster de mise en service.<br/><br/><b>Mot de passe utilisateur Hadoop</b> : Spécifie les informations d’identification utilisées lors de la configuration du cluster. Pour plus d’informations, voir [Hadoop créer des groupes dans un HDInsight](../hdinsight/hdinsight-provision-clusters.md).<br/><br/><b>Emplacement des données de sortie</b>: indique si les données sont stockées dans un système de fichiers Hadoop distribué (HDFS) ou dans Azure. <br/><ul>Si vous stockez les données de sortie dans HADOOP, spécifiez le serveur HADOOP URI. (Veillez à utiliser le nom du cluster HDInsight sans le préfixe HTTPS://). <br/><br/>Si vous stockez vos données de sortie dans Azure, vous devez spécifier le nom de compte de stockage Azure, la touche d’accès de stockage et le nom de conteneur stockage.</ul>|
Base de données SQL |Lit les données qui sont stockées dans une base de données SQL Azure ou dans une base de données SQL Server s’exécutant sur une machine virtuelle Azure. | <b>Nom du serveur de base de données</b>: Spécifie le nom du serveur sur lequel la base de données est en cours d’exécution.<br/><ul>En cas de base de données SQL Azure, entrez le nom du serveur qui est généré. Généralement qu’il possède le formulaire * &lt;generated_identifier&gt;. database.windows.net.* <br/><br/>Dans le cas d’un serveur SQL server hébergé sur un ordinateur virtuel Azure entrez *tcp :&lt;nom DNS Machine virtuelle&gt;, 1433*</ul><br/><b>Nom de la base de données </b>: Spécifie le nom de la base de données sur le serveur. <br/><br/><b>Nom du compte utilisateur Server</b>: Spécifie un nom d’utilisateur pour un compte disposant des autorisations d’accès de la base de données. <br/><br/><b>Mot de passe utilisateur Server</b>: Spécifie le mot de passe pour le compte d’utilisateur.<br/><br/><b>Accepter n’importe quel certificat du serveur</b>: utilisez cette option (moins sécurisée) si vous souhaitez ignorer Examinez le certificat de site avant de lire vos données.<br/><br/><b>Requête de base de données</b>: entrez une instruction SQL qui décrit les données que vous souhaitez lire.|
Base de données locale SQL |Lit les données qui sont stockées dans une base de données SQL locale. | <b>Passerelle de données</b>: Spécifie le nom de la passerelle de gestion des données installé sur l’ordinateur où il peut accéder à votre base de données SQL Server. Pour plus d’informations sur la configuration de la passerelle, voir [effectuer avancées analytique avec apprentissage automatique Azure à l’aide de données à partir d’un serveur SQL local](machine-learning-use-data-from-an-on-premises-sql-server.md).<br/><br/><b>Nom du serveur de base de données</b>: Spécifie le nom du serveur sur lequel la base de données est en cours d’exécution.<br/><br/><b>Nom de la base de données </b>: Spécifie le nom de la base de données sur le serveur. <br/><br/><b>Nom du compte utilisateur Server</b>: Spécifie un nom d’utilisateur pour un compte disposant des autorisations d’accès de la base de données. <br/><br/><b>Nom d’utilisateur et mot de passe</b>: cliquez sur <b>Entrez des valeurs</b> à entrer vos informations d’identification de base de données. Vous pouvez utiliser l’authentification Windows ou l’authentification SQL Server selon la manière dont est configuré votre SQL Server locale.<br/><br/><b>Requête de base de données</b>: entrez une instruction SQL qui décrit les données que vous souhaitez lire.|
Table Azure|Lit les données à partir du service de Table dans le stockage Azure.<br/><br/>Si vous lisez rarement grandes quantités de données, utilisez le Service de Table Azure. Il propose un flexible non relationnelles (NoSQL), solution de stockage hautement scalable, peu coûteux et hautement disponible.| Les options dans les **Importer des données** varient selon que vous accédiez informations publiques ou un compte de stockage privé qui nécessite des informations d’identification. Cela est déterminé par le <b>Type d’authentification</b> qui peut avoir la valeur de « PublicOrSAS » ou « Compte », dont chacune possède son propre jeu de paramètres. <br/><br/><b>Publics ou partagés accès Signature (sa) URI</b>: les paramètres sont :<br/><br/><ul><b>Table URI</b>: Spécifie le Public ou l’URL associations de sécurité pour la table.<br/><br/><b>Spécifie les lignes pour rechercher les noms de propriété</b>: les valeurs sont <i>TopN</i> pour analyser le nombre spécifié de lignes ou <i>ScanAll</i> pour obtenir toutes les lignes du tableau. <br/><br/>Si les données sont prévisibles et homogène, il est recommandé que vous sélectionnez *TopN* et entrez un nombre N. Pour les tables volumineuses, cela peut entraîner plus rapidement les temps de lecture.<br/><br/>Si les données sont structurées avec des ensembles de propriétés qui varient en fonction de la profondeur et la position de la table, choisissez l’option *ScanAll* de recherche toutes les lignes. Cela garantit l’intégrité de votre propriété résultante et la conversion de métadonnées.<br/><br/></ul><b>Compte de stockage privé</b>: les paramètres sont : <br/><br/><ul><b>Nom de compte</b>: Spécifie le nom du compte qui contient la table à lire.<br/><br/><b>Clé de compte</b>: Spécifie la clé de stockage associée au compte.<br/><br/><b>Nom de la table</b> : indique le nom de la table qui contient les données à lire.<br/><br/><b>Lignes pour rechercher les noms de propriété</b>: les valeurs sont <i>TopN</i> pour analyser le nombre spécifié de lignes ou <i>ScanAll</i> pour obtenir toutes les lignes du tableau.<br/><br/>Si les données sont prévisibles et homogène, nous vous recommandons que vous sélectionnez *TopN* et entrez un nombre N. Pour les tables volumineuses, cela peut entraîner plus rapidement les temps de lecture.<br/><br/>Si les données sont structurées avec des ensembles de propriétés qui varient en fonction de la profondeur et la position de la table, choisissez l’option *ScanAll* de recherche toutes les lignes. Cela garantit l’intégrité de votre propriété résultante et la conversion de métadonnées.<br/><br/>|
Stockage d’objets Blob Azure | Lit les données stockées dans le service d’objets Blob dans le stockage Azure, y compris les images, le texte non structurée ou données binaires.<br/><br/>Vous pouvez utiliser le service Blob publiquement exposer des données, ou pour stocker les données d’application en privé. Vous pouvez accéder à vos données à partir de n’importe quel emplacement à l’aide de connexions HTTP ou HTTPS. | Les options dans le module **Importer des données** varient selon que vous accédiez informations publiques ou un compte de stockage privé qui nécessite des informations d’identification. Cela est déterminé par le <b>Type d’authentification</b> qui peut avoir une valeur de « PublicOrSAS » ou « Compte ».<br/><br/><b>Publics ou partagés accès Signature (sa) URI</b>: les paramètres sont :<br/><br/><ul><b>URI</b>: Spécifie le Public ou l’URL de sa pour le blob de stockage.<br/><br/><b>Format de fichier</b>: Spécifie le format des données dans le service d’objets Blob. Les formats pris en charge sont CSV et TSV ARFF.<br/><br/></ul><b>Compte de stockage privé</b>: les paramètres sont : <br/><br/><ul><b>Nom de compte</b>: Spécifie le nom du compte qui contient le blob que vous souhaitez lire.<br/><br/><b>Clé de compte</b>: Spécifie la clé de stockage associée au compte.<br/><br/><b>Chemin d’accès au conteneur, répertoire ou blob</b> : Spécifie le nom de l’objet blob qui contient les données à lire.<br/><br/><b>Format de fichier BLOB</b>: Spécifie le format des données dans le service d’objets blob. Les formats de données pris en charge sont CSV, TSV, ARFF, CSV avec un codage spécifié et Excel. <br/><br/><ul>Si le format est CSV ou TSV, veillez à indiquer si le fichier contient une ligne d’en-tête.<br/><br/>Vous pouvez utiliser l’option d’Excel pour lire les données dans des classeurs Excel. Dans l’option de <i>format des données Excel</i> , vous pouvez indiquer si les données sont dans une plage de feuille de calcul Excel ou dans un tableau Excel. L’option <i>feuille de calcul Excel ou tableau incorporé </i>, indiquez le nom de la feuille ou le tableau que vous souhaitez lire.</ul><br/>|
Fournisseur de flux de données | Lit les données à partir d’un fournisseur de flux pris en charge. Actuellement pris en charge uniquement le format Open Data Protocol (OData). | <b>Type de contenu de données</b>: Spécifie le format OData.<br/><br/><b>URL de la source</b>: Spécifie l’URL complète du flux de données. <br/>Par exemple, l’URL suivante lit à partir de la base de données exemple Northwind : http://services.odata.org/northwind/northwind.svc/|


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[export-data]: https://msdn.microsoft.com/library/azure/7A391181-B6A7-4AD4-B82D-E419C0D6522C/
