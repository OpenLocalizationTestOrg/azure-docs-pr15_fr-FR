<properties
   pageTitle="Liste de vérification extensibilité élevées | Microsoft Azure"
   description="Conseils de liste de vérification extensibilité élevées pour les problèmes de conception pour Autoscaling Azure."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="christb"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="07/13/2016"
   ms.author="masashin"/>

# <a name="scalability-checklist"></a>Liste de vérification extensibilité élevées

[AZURE.INCLUDE [pnp-header](../includes/guidance-pnp-header-include.md)]

## <a name="service-design"></a>Création de service
- **Partition la charge de travail**. Créer des parties de la procédure à suivre pour être discrète et DÉCOMPOSABLES. Réduire la taille de chaque composant, en suivant les règles habituelles séparation des problèmes et le principe de responsabilité unique. Ainsi, les composants doit être distribué de façon à optimiser l’utilisation de chaque unité cluster (par exemple, un serveur de base de données ou rôle). Il facilite également à l’échelle de l’application en ajoutant des instances de ressources spécifiques. Pour plus d’informations, voir [Recommandations pour la partition calculer](https://msdn.microsoft.com/library/dn589773.aspx).
- **Création d’échelle**. Mise à l’échelle permet aux applications de réagir à charge variable en augmentant et en réduisant le nombre d’instances des rôles, des files d’attente, et d’autres services qu’ils utilisent. Toutefois, l’application doit être conçue avec ce à l’esprit. Par exemple, l’application et les services qu’elle utilise doivent être sans état, qui autorise les requêtes routés vers n’importe quelle instance. Cela empêche également l’ajout ou la suppression des instances spécifiques d’avoir un impact sur les utilisateurs en cours. Vous devez également implémenter configuration ou la détection automatique des instances comme ils sont ajoutés ou supprimés, afin que le code dans l’application puisse effectuer le routage nécessaire. Par exemple, une application web peut-être utiliser un ensemble de files d’attente dans une approche cyclique pour acheminer les requêtes aux services d’arrière-plan en cours d’exécution dans les rôles de travail. L’application web doit être en mesure de détecter les modifications dans le nombre de files d’attente, pour acheminer les demandes et équilibrer la charge sur l’application.
- **Échelle en tant qu’unité**. Plan des ressources supplémentaires suivre la croissance. Pour chaque ressource, connaître le coin supérieur mise à l’échelle des limites et utilisez ont ou décomposition d’aller au-delà de ces limites. Déterminer l’unité d’échelle du système en termes de bien définis ensembles de ressources. Cela rend application horizontale plus facile et moins propice aux conséquences sur l’application via les limitations imposées par manque de ressources dans une partie de l’ensemble du système. Par exemple, ajout x nombre de rôles web et collaborateur peut nécessiter un nombre y de files d’attente supplémentaires et le nombre de z de comptes de stockage pour gérer la charge de travail supplémentaire générée par les rôles. Pour une unité d’échelle peut comporter x rôles web et collaborateur _y_ files d’attente et des comptes de stockage _z_ . Concevoir l’application afin qu’elle est redimensionnée facilement en ajoutant une ou plusieurs unités d’échelle.
- **Évitez d’affinité du client**. Si possible, assurez-vous que l’application ne requiert pas affinité. Demandes peuvent donc être routés vers n’importe quelle instance, et le nombre d’instances est sans pertinence. Cela évite également de stockage, extraction et gestion des informations d’état pour chaque utilisateur.
- **Tirer parti des fonctionnalités d’autoscaling plateforme**. Où la plateforme d’hébergement prend en charge une fonctionnalité autoscaling, telles qu’échelle Azure, vous préférez effectuer une mécanismes personnalisés ou tiers, sauf si le mécanisme intégré ne peut pas répondre à vos besoins. Utiliser des règles de mise à l’échelle planifiées où pour s’assurer que les ressources sont disponibles sans un délai de démarrage, mais ajoutez autoscaling réactive aux règles le cas échéant pour s’adapter aux changements inattendus dans la demande. Vous pouvez utiliser les opérations autoscaling dans l’API de gestion de Service pour régler autoscaling et ajouter des compteurs personnalisés aux règles. Pour plus d’informations, voir [recommandations pour la mise à l’échelle](best-practices-auto-scaling.md).
- **Décharger intensive du processeur/IO tâches sous forme de tâches en arrière-plan**. Si une demande d’un service doit prendre beaucoup de temps à s’exécuter ou retirer des ressources considérables, décharger le traitement de cette demande à une tâche distincte. Utiliser des rôles de travail ou des travaux en arrière-plan (selon la plateforme d’hébergement) pour exécuter ces tâches. Cette stratégie permet au service de continuer à recevoir des requêtes et rester injoignable.  Pour plus d’informations, voir [recommandations pour les travaux de l’arrière-plan](best-practices-background-jobs.md).
- **Répartir la charge de travail pour les tâches en arrière-plan**. Où il existe de nombreuses tâches en arrière-plan, ou les tâches nécessitent beaucoup de temps ou des ressources, répartir le travail sur plusieurs unités cluster (par exemple, les rôles de travail ou les tâches en arrière-plan). Pour une solution possible, voir la [Concurrence consommateurs motif](https://msdn.microsoft.com/library/dn568101.aspx).
- **Pensez vers un _sans partage_ architecture**. Une architecture sans partage utilise des nœuds indépendantes, autonomes qui ne possèdent aucun point de conflit (par exemple, les services partagés ou stockage) unique. Dans les principes, un tel système peut évoluer quasiment indéfiniment. Une approche sans entièrement partage n’est généralement pas pratique pour la plupart des applications, elle peut fournir les opportunités de conception pour une meilleure extensibilité élevées. Par exemple, pour éviter d’obtenir l’utilisation de l’état de session côté serveur, affinité du client et division des données sont des exemples de déplacement vers une architecture sans partage.

## <a name="data-management"></a>Gestion des données

- **Utiliser les données partition**. Diviser les données dans plusieurs bases de données et les serveurs de base de données ou la conception de l’application pour utiliser le stockage de données services qui peut fournir cette répartition en toute transparence (et des exemples de la base de données élastique de base de données SQL Azure, stockage de Table Azure). Cette approche peut vous aider à optimiser les performances et autoriser la mise à l’échelle plus facilement. Il existe différentes partition techniques, par exemple horizontal, vertical et fonctionnelle. Vous pouvez utiliser une combinaison de ces pour atteindre le meilleur parti de performances des requêtes accrue extensibilité du plus simple, plus flexible, la gestion une plus grande disponibilité et pour faire correspondre le type de magasin aux données qu’il contiendra. En outre, envisagez d’utiliser différents types de magasin de données pour différents types de données, en choisissant les types en fonction de la façon dont ils sont optimisés pour le type de données spécifique. Cela peut inclure à l’aide de stockage de table, une base de données du document ou un magasin de données de colonne famille à la place, ou ainsi comme une base de données relationnelle. Pour plus d’informations, voir [recommandations pour partition de données](best-practices-data-partitioning.md).
- **Conception pour la cohérence éventuelle**. La cohérence éventuelle améliore extensibilité élevées en réduisant ou en supprimant le temps nécessaire pour synchroniser des données associées partitionnées sur plusieurs magasins. Le coût est que données ne sont pas toujours cohérentes lorsque celui-ci est lu, et certaines écrivez opérations peuvent entraîner des conflits. La cohérence éventuelle est idéale dans les situations où les mêmes données sont lus fréquemment, mais écrites rarement. Pour plus d’informations, voir l' [Introduction à la cohérence des données](https://msdn.microsoft.com/library/dn589800.aspx).
- **Réduire amenées interactions entre les composants et services**. Éviter de concevoir des interactions dans lequel une application est requise pour émettre des appels multiples à un service (chacun d'entre eux renvoie une petite quantité de données), plutôt qu’un seul appel qui peut renvoyer toutes les données. Si possible, combinez plusieurs opérations associées dans une seule demande quand l’appel est à un service ou d’un composant qui a latence visible. Cela facilite la surveiller les performances et optimiser les opérations complexes. Par exemple, utilisez les procédures stockées dans les bases de données pour encapsuler une logique complexe et réduire le nombre de boucles et verrouillage des ressources.
- **Utiliser des files d’attente pour niveler la charge pour les opérations haute vitesse**. Pointes dans la demande d’un service peuvent surcharger ce service et entraîner des erreurs croissantes. Pour éviter ce problème, envisagez d’implémenter le [modèle de l’audit charge file d’attente](https://msdn.microsoft.com/library/dn589783.aspx). Utiliser une file d’attente qui sert de tampon entre une tâche et un service qu’il appelle. Cela peut lisses intermittents charges qui peuvent dans le cas contraire entraîner l’échec du service ou la tâche délai d’expiration.
- **Réduire la charge sur le magasin de données**. Le magasin de données est généralement un traitement critique, une ressource coûteuse et pas souvent facile à évoluer. Si possible, supprimez logique (par exemple, le traitement des documents XML ou objets JSON) à partir du magasin de données et traiter les données dans l’application. Par exemple, au lieu de passage XML vers la base de données (autres que ceux qui une chaîne opaque pour le stockage), sérialiser ou désérialiser le XML au sein de la couche d’application et passer dans un formulaire qui est natif au magasin de données. Il est généralement beaucoup plus facile à l’échelle de l’application que le magasin de données, afin que vous devez essayer d’effectuer autant de la transformation de cluster accrue que possible dans l’application.
- **Réduire le volume de données récupérées**. Récupérer uniquement les données souhaitées en spécifiant des colonnes et des critères pour sélectionner des lignes. Vérifiez l’utilisation des paramètres de valeur la table et le niveau d’isolement. Mécanismes utiliser comme balises d’entités pour éviter l’extraction des données inutilement.
- **Agressif utiliser la mise en cache**. Utiliser la mise en cache lorsque cela est possible de réduire la charge sur les ressources et services générer ou de fournissent des données. La mise en cache est généralement adapté aux données qui est relativement statique, ou qui nécessite un traitement considérable pour obtenir. La mise en cache doit avoir lieu à tous les niveaux le cas échéant dans chaque calque de l’application, notamment génération d’interface utilisateur et accès aux données. Pour plus d’informations, consultez le [Guide de mise en cache](best-practices-caching.md).
- **Gérer la croissance des données et la rétention**. La quantité de données stockées par une application augmente au fil du temps. Cette croissance augmente les coûts de stockage et augmentation de la latence lors de l’accès aux données — qui affecte débit de l’application et les performances. Il est possible d’archivage certaines des anciennes données qui n’est plus accessible, ou déplacer des données qui se trouve rarement dans le stockage à long terme qui est plus économique, même si la latence d’accès est plus élevée.
- **Optimiser transférer des objets de données (DTO) à l’aide d’un format binaire efficace**. DTO sont passées entre les couches d’une application autant de fois. En réduisant la taille réduit la charge sur les ressources et le réseau. Toutefois, équilibrer les économies avec la charge de conversion des données dans le format requis dans chaque emplacement où il est utilisé. Adopter un format qui inclut l’interopérabilité maximale pour activer faciliter leur réutilisation d’un composant.
- **Définir le contrôle de cache**. Concevoir et configurer l’application pour utiliser la mise en cache de sortie ou fragment si possible réduire la charge de traitement de mise en cache.
- **Activer la mise en cache côté client**. Applications Web doivent activer les paramètres de cache sur le contenu pouvant être mis en cache. Ceci est généralement désactivée par défaut. Configurer le serveur pour présenter des en-têtes de contrôle pour activer la mise en cache du contenu sur les clients et les serveurs proxy le cache approprié.
- **Stockage d’objets blob Azure utilisation et le réseau de distribution de contenu Azure pour réduire la charge sur l’application**. Envisagez de stocker un contenu public statique ou relativement statique, tels que des images, des ressources, des scripts et des feuilles de style, dans le stockage blob. Cette approche évite l’application de la charge causée par génération dynamique ce contenu pour chaque demande. En outre, envisagez d’utiliser le réseau de distribution de contenu pour mettre en cache ce contenu et offrir aux clients. À l’aide du réseau de distribution de contenu peut améliorer les performances au niveau du client, car le contenu est remis à partir du centre de données le plus proche géographiquement qui contient un cache de réseau de distribution de contenu. Pour plus d’informations, consultez le [Contenu conseils de réseau de remise](best-practices-cdn.md).
- **Optimisation et réglage des requêtes SQL et index**. Quelques instructions T-SQL ou constructions peuvent avoir un impact sur les performances peuvent être réduits en optimisant le code dans une procédure stockée. Par exemple, évitez d’en convertissant les types **date/heure** en un **varchar** avant de le comparer avec une valeur littérale de **date/heure** . Utilisez les fonctions de comparaison de date/heure à la place. Absence d’index appropriés peut également ralentir l’exécution des requêtes. Si vous utilisez une infrastructure de mappage relationnel/objet, comprendre comment cela fonctionne et comment il peut affecter les performances de la couche d’accès aux données. Pour plus d’informations, voir [Analyse de requêtes](https://technet.microsoft.com/library/ms176005.aspx).
- **Pensez à désactiver normalisation des données**. Normalisation des données permet d’éviter les doublons et incohérence. Toutefois, la conservation de plusieurs index, vérification de l’intégrité référentielle, effectuer plusieurs accès à faible quantité de données et joindre des tables pour rassembler les données impose une surcharge qui peut affecter les performances. Déterminez si certains volume d’espace de stockage supplémentaire et duplication est acceptable afin de réduire la charge sur le magasin de données. Envisagez également si l’application elle-même (qui est généralement plus facile à mettre à l’échelle) peut faire confiance à prendre le contrôle tâches telles que la gestion de l’intégrité référentielle afin de réduire la charge sur le magasin de données. Pour plus d’informations, voir [recommandations pour partition de données](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md).

## <a name="service-implementation"></a>Implémentation du service
- **Utiliser des appels asynchrones**. Utiliser code asynchrone autant que possible lors de l’accès aux ressources ou aux services qui peuvent être limitées par e/s ou la bande passante réseau ou qui ont une latence visible, afin d’éviter de verrouiller le thread d’appel. Pour mettre en œuvre des opérations asynchrones, utilisez le [Motif asynchrone basée sur une tâche (clic)](https://msdn.microsoft.com/library/hh873175.aspx).
- **Éviter de verrouiller les ressources et utiliser une approche optimiste à la place**. Ne jamais verrouille l’accès aux ressources, comme le stockage ou autres services qui ont une latence visible, car il s’agit d’une cause principale d’une baisse des performances. Toujours utiliser les durées optimistes approches de gestion des opérations simultanées, telles que l’écriture de stockage. Utiliser les fonctionnalités de la couche de stockage pour gérer les conflits. Dans les applications distribuées, données peuvent être uniquement finalement cohérentes.
- **Compresser des données fortement compressibles via une latence élevée, réseaux de faible bande passante**. Dans la plupart des cas dans une application web, le plus grand volume de données générées par l’application et transmises sur le réseau est des réponses aux demandes des clients HTTP. Compression HTTP permet de réduire ce considérablement, en particulier pour le contenu statique. Cela peut réduire le coût, ainsi que la réduction de la charge sur le réseau, bien que la compression de contenu dynamique applique-t-elle une charge EGALISEURS plus élevée sur le serveur. Dans les environnements GRG plus, compression de données peut réduire le volume de données transmises et réduire les délais de transfert et les coûts, mais les processus de compression et décompression subir une charge. Dès lors, compression doit uniquement être utilisée lorsqu’il y a un gain accompli des performances. Autres méthodes de sérialisation, tels que JSON ou des codages binaires, peuvent réduire la taille de charge utile tout en ayant un impact réduit sur les performances, alors que XML est susceptible d’augmenter.
- **Réduire la durée des connexions et ressources sont en cours d’utilisation**. Mettre à jour les connexions et les ressources uniquement dans la mesure où vous devez utiliser les. Par exemple, ouvrez connexions plus tard possible et lui permettre d’être retournée au pool de connexion dès que possible. Obtenir des ressources plus tard possible, puis céder dès que possible.
- **Réduire le nombre de connexions requis**. Connexions aux services retirer des ressources. Limiter le nombre requis et vous assurer que les connexions existantes sont réutilisées dès que possible. Par exemple, après avoir exécuté l’authentification, utilisez l’emprunt d’identité le cas échéant à exécuter du code dans une identité spécifique. Cela peut vous aider à tirer le meilleur parti de regroupement de connexion en réutiliser les connexions.

    > [AZURE.NOTE]: APIs for some services automatically reuse connections, provided service-specific guidelines are followed. It's important that you understand the conditions that enable connection reuse for each service that your application uses.

- **Envoyer des demandes de lots pour optimiser l’utilisation du réseau**. Par exemple, envoyer et lire les messages par lots lorsque vous accédez à une file d’attente et effectuer plusieurs lectures ou écritures comme un lot lorsque vous accédez à l’espace de stockage ou d’un cache. Cela peut vous aider à maximiser l’efficacité des banques de données et des services en réduisant le nombre d’appels sur le réseau.
- **Évitez de développer pour stocker l’état de session côté serveur** lorsque cela est possible. Gestion de l’état session côté serveur en général requiert client (qui est, routage chaque demande à la même instance de serveur), ce qui affecte la capacité du système à l’échelle. Dans l’idéal, vous devez concevoir des clients sans état en ce qui concerne les serveurs qu’ils utilisent. Toutefois, si l’application doit maintenir un état de session, stocker des données sensibles ou grands volumes de données par client dans un cache distribué côté serveur qui peuvent accéder à toutes les instances de l’application.
- **Optimiser les schémas de stockage de table**. Lors de l’utilisation de banques de table qui requièrent les noms des tables et des colonnes à transmettre et traitées avec chaque requête, tels que de stockage de table Azure, envisagez d’utiliser des noms plus courte et à réduire cette surcharge. Toutefois, sacrifice pas lisibilité et facilité de gestion à l’aide de noms trop compact.
- **Utiliser la bibliothèque (parallèle de tâches) pour effectuer les opérations asynchrones**. La bibliothèque parallèle de tâches facilite l’écrire du code asynchrone qui effectue les opérations e/S. Utilisez _ConfigureAwait (false)_ dès que possible afin d’éliminer la dépendance de continuation dans un contexte de synchronisation spécifique. Cela permet de réduire les risques de blocage de thread se produisant.
- **Créer des dépendances de ressource au cours du déploiement ou au démarrage de l’application**. Éviter les appels répétés à des méthodes tester l’existence d’une ressource, puis créez la ressource s’il n’existe pas. (Méthodes tels que _CloudTable.CreateIfNotExists_ et _CloudQueue.CreateIfNotExists_ dans la bibliothèque de Client de stockage Azure suivent ce modèle). Ces méthodes peuvent affecter les considérable si elles sont appelées avant chaque accès à un tableau de stockage ou file d’attente de stockage. Procédez comme suit :
 - Créer les ressources requises lorsque l’application est déployée ou lors du premier démarrage (un seul appel à _CreateIfNotExists_ pour chaque ressource dans le code de démarrage pour un rôle web ou de travail est acceptable). Toutefois, veillez à gérer les exceptions qui peuvent survenir si votre code tente d’accéder à une ressource qui n’existe pas. Dans ce cas, vous devez enregistrer l’exception et prévenir un opérateur qu’il manque une ressource.
 - Dans certaines circonstances, il peut être approprié créer la ressource manquante dans le cadre de la gestion des code exceptions. Mais cette approche avec prudence à adopter comme l’existence hors de la ressource peut être le signe d’une erreur de programmation (un nom de ressource mal orthographiés par exemple) ou un autre problème au niveau de l’infrastructure.
- **Structures légères d’utilisation**. Choisissez avec soin les API et les structures que vous permet de réduire l’utilisation des ressources, temps d’exécution et charge totale sur l’application. Par exemple, à l’aide de l’API Web pour gérer les demandes de service peut réduire l’encombrement de l’application et augmenter la vitesse d’exécution, mais il peut ne pas être approprié pour des scénarios avancés où les fonctionnalités supplémentaires de Windows Communication Foundation sont requises.
- **Pensez à réduire le nombre de comptes de service**. Par exemple, utilisez un compte spécifique pour accéder aux ressources ou services qui imposent une limite de connexions ou effectuer une meilleure où moins de connexions sont conservées. Cette approche est courante pour les services tels que des bases de données, mais il peut affecter la capacité à auditer précisément les opérations effectuées en raison de l’emprunt d’identité de l’utilisateur d’origine.
- **Effectuer des tests de charge et de performances profil** pendant le développement, dans le cadre de routines de test et avant la version finale pour garantir que l’application effectue et échelles selon les besoins. Ce test doit avoir lieu sur le même type de matériel en tant que la plateforme de production et avec les mêmes types et quantités de données et d’utilisateur chargement comme il sera rencontrer en production. Pour plus d’informations, voir [tester les performances d’un service cloud](vs-azure-tools-performance-profiling-cloud-services.md).
